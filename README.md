ğŸ“„ **README.md**


# ğŸ“˜ **Data Quality Agent Pipeline â€“ Capstone Project**

## ğŸš€ Overview

The **Data Quality Agent Pipeline** is an automated system designed to ensure that any datasetâ€”raw, messy, or incompleteâ€”can be processed and transformed into a *clean, validated, and analysis-ready* format.

This project uses a modular **Agent-based architecture**, where each agent is responsible for a specific task:

* ğŸŸ¦ **Ingestion Agent** â€“ loads the raw dataset
* ğŸŸ© **Quality Check Agent** â€“ identifies missing values, invalid types, and structural issues
* ğŸŸ¨ **AutoFix Agent** â€“ applies automated cleaning & fixes
* ğŸŸ§ **Validation Agent** â€“ generates a validation report
* ğŸŸª **Reporting Agent** â€“ outputs pipeline results

The pipeline is built in Python and can handle **any CSV dataset**, making it ideal for real-world data work, ETL processes, production workflows, and Kaggle competitions.

---

## ğŸ§  Key Features

âœ” Modular agent-based system
âœ” Fully automated end-to-end pipeline
âœ” Ingestion, cleaning, validation, and reporting
âœ” Works with any CSV file
âœ” Generates output files automatically
âœ” Easy to integrate into data engineering workflows
âœ” Beginner-friendly & production-ready structure

---

## ğŸ“‚ Project Structure

```
data-quality-agent-capstone/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ quality_check_agent.py
â”‚   â”œâ”€â”€ autofix_agent.py
â”‚   â”œâ”€â”€ validation_agent.py
â”‚   â”œâ”€â”€ reporting_agent.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ raw.csv
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ cleaned.csv
â”‚       â”œâ”€â”€ validation_report.json
â”‚       â””â”€â”€ summary.txt
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agents.py
â”‚
â””â”€â”€ tools/
    â””â”€â”€ helpers.py
```

---

## ğŸ›  Requirements

### ğŸ”§ Software

Install these on Windows:

* Python 3.10+
* pip
* Git
* VS Code (optional but recommended)

### ğŸ“¦ Python Libraries

Install using:

```
pip install -r requirements.txt
```

(If you donâ€™t have the file, your project only needs pandas.)

---

## â–¶ï¸ How to Run the Pipeline

### **Step 1 â€“ Place your dataset**

Put a CSV file into:

```
data/input/raw.csv
```

Example:

```
data/input/raw.csv
```

### **Step 2 â€“ Run the app**

Open CMD or VS Code terminal:

```
python app.py
```

### âœ” You should see:

```
=== DATA QUALITY AGENT PIPELINE STARTED ===

[STEP 1] Ingestion completed.
[STEP 2] Quality Check completed.
[STEP 3] Autofix completed.
[STEP 4] Validation completed.

=== PIPELINE FINISHED SUCCESSFULLY ===
```

### **Step 3 â€“ Check the outputs**

After running, check:

```
data/output/cleaned.csv
data/output/validation_report.json
data/output/summary.txt
```

## ğŸ§ª Tests

To run tests:

```
python -m pytest tests/
```

## ğŸ§© Agents Explained

### 1ï¸âƒ£ Ingestion Agent

Loads the input CSV.

### 2ï¸âƒ£ Quality Check Agent

Runs basic checks:

* Null counts
* Datatype info
* Summary statistics

### 3ï¸âƒ£ AutoFix Agent

Applies simple fixes:

* Fills missing values
* Saves cleaned file

### 4ï¸âƒ£ Validation Agent

Creates a structured validation report:

```
{
  "rows": 100,
  "columns": ["A","B","C"],
  "missing_values": { ... }
}
```

### 5ï¸âƒ£ Reporting Agent

Produces a simple text summary.

## Why This Project Stands Out

âœ” Real-world ETL pipeline
âœ” Fully automated
âœ” Agent-based clean architecture
âœ” Works on any dataset
âœ” Beginner-friendly but industry-oriented
âœ” Modular for future extension


## Author

**kiran**
(Data Engineering Enthusiast)
